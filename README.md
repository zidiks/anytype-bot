# ðŸŽ¤ Anytype Voice Notes Bot

Telegram bot that transcribes voice messages, generates AI summaries, and saves everything to Anytype.

## Features

- ðŸŽ¤ **Voice Transcription** â€” Self-hosted speech-to-text using faster-whisper
- ðŸ¤– **AI Summarization** â€” Generates concise summaries via DeepSeek API
- ðŸ’¾ **Anytype Integration** â€” Saves notes with summary + full transcription
- ðŸ”— **Auto-linking** â€” Automatically adds references to your notes collection

## Architecture

```
Voice Message â†’ Telegram Bot â†’ Whisper (transcription) â†’ DeepSeek (summary) â†’ Anytype (storage)
```

## Quick Start

### 1. Clone and Configure

```bash
git clone <repo>
cd anytype-bot

# Copy environment template
cp env.example .env

# Edit .env with your credentials
```

### 2. Configure Environment

Edit `.env` file:

```env
# Telegram Bot (get from @BotFather)
TELEGRAM_BOT_TOKEN=your_token

# Anytype API
ANYTYPE_API_URL=http://89.40.5.115:31012
ANYTYPE_BEARER_TOKEN=your_anytype_token
ANYTYPE_SPACE_ID=your_space_id
ANYTYPE_NOTES_OBJECT_ID=your_notes_collection_id

# DeepSeek API
DEEPSEEK_API_KEY=your_deepseek_key

# Whisper (local or api)
WHISPER_MODE=local
WHISPER_MODEL=base

# Optional: Restrict to specific users
ALLOWED_USER_IDS=123456789,987654321
```

### 3. Run with Docker (Recommended)

**Option A: With separate Whisper container (recommended for production)**

```bash
docker-compose up -d
```

This starts:
- `anytype-voice-bot` â€” The Telegram bot
- `anytype-whisper` â€” Self-hosted Whisper ASR on port 9000

**Option B: With local Whisper (single container)**

```bash
docker-compose -f docker-compose.local.yml up -d
```

### 4. Run Locally (Development)

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt

# Install ffmpeg (required for audio processing)
# Ubuntu: sudo apt install ffmpeg
# macOS: brew install ffmpeg
# Windows: choco install ffmpeg

# Run
python run.py
```

## Usage

1. Start a chat with your bot on Telegram
2. Send `/start` to see the welcome message
3. Record and send a voice message
4. Bot will:
   - Download and transcribe the audio
   - Generate an AI summary
   - Create a new note in Anytype
   - Add a reference to your notes collection

## Anytype Note Structure

Each voice note is saved as:

```markdown
## Summary
[AI-generated summary]

---

## Full Transcription
> [Complete transcribed text as a quote block]
```

The note is automatically linked to your main notes collection (Volodya's Notes).

## Self-Hosted Whisper Options

### Option 1: Integrated faster-whisper (Default)

Runs inside the bot container. Good for:
- Single-server deployments
- Lower resource environments

```env
WHISPER_MODE=local
WHISPER_MODEL=base  # tiny, base, small, medium, large-v3
```

### Option 2: Separate Whisper Service

Uses [openai-whisper-asr-webservice](https://github.com/ahmetoner/whisper-asr-webservice). Good for:
- Multiple bots sharing one Whisper instance
- GPU-accelerated transcription
- Scaling independently

```env
WHISPER_MODE=api
WHISPER_API_URL=http://whisper:9000
```

### Model Size Comparison

| Model | Size | RAM | Speed | Accuracy |
|-------|------|-----|-------|----------|
| tiny | 39M | ~1GB | Fastest | Basic |
| base | 74M | ~1GB | Fast | Good |
| small | 244M | ~2GB | Medium | Better |
| medium | 769M | ~5GB | Slow | Great |
| large-v3 | 1.5GB | ~10GB | Slowest | Best |

## Project Structure

```
anytype-bot/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ bot.py           # Main Telegram bot
â”‚   â”œâ”€â”€ config.py        # Configuration loader
â”‚   â”œâ”€â”€ anytype_client.py # Anytype API client
â”‚   â”œâ”€â”€ transcription.py  # Whisper transcription
â”‚   â””â”€â”€ summarizer.py     # DeepSeek summarization
â”œâ”€â”€ run.py               # Entry point
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Dockerfile.local
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docker-compose.local.yml
â””â”€â”€ env.example
```

## API Reference

### Anytype API

Based on [Anytype Developer Documentation](https://developers.anytype.io/docs/reference):

- `POST /spaces/{space_id}/objects` â€” Create new object
- `GET /spaces/{space_id}/objects/{object_id}` â€” Get object
- `PATCH /spaces/{space_id}/objects/{object_id}` â€” Update object
- `GET /spaces/{space_id}/types` â€” List available types

### DeepSeek API

OpenAI-compatible API at `https://api.deepseek.com/v1`:

- `POST /chat/completions` â€” Generate summary

## Troubleshooting

### "Could not transcribe the audio"

- Ensure ffmpeg is installed
- Check that the voice message has clear audio
- Try a larger Whisper model

### Anytype API errors

- Verify your bearer token is correct
- Check that the space ID and object IDs exist
- Ensure your Anytype server is accessible

### DeepSeek API errors

- Verify your API key is valid
- Check your API quota/limits

## License

MIT
